# 얼굴 인식 프로그램

실행 순서는 part1부터 3까지.

## OpenCV 라이브러리를 사용함

OpenCV는 오픈 소스 컴퓨터 비전 및 머신러닝 소프트웨어 라이브러리입니다. (실시간 이미지 프로세싱에 중점을 둔 라이브러리)
라이브러리에는 2,500개 이상의 최적화 된 최첨단 컴퓨터 비전, 머신러닝 그리고 고전적인 알고리즘이 포함되어 있습니다. 이러한 알고리즘들을 통해서 얼굴 감지 및 인식, 물체 식별, 비디오에서 사람 행동 분류, 카메라 움직임 추적, 다수의 물체에서 움직이는 물체를 추적 등을 할 수 있습니다.

본 프로젝트에서 사용한 OpenCV는 4.5.0 버전을 사용했습니다.

OpenCV 사용과 본 프로젝트에 사용할 패키지 또는 서브 라이브러리 등들 설치합니다.
- build-essential : 패키지에는 C/C++ 컴파일러와 관련 라이브러리, make 같은 도구들이 포함되어 있습니다.
cmake는 컴파일 옵션이나 빌드된 라이브러리에 포함시킬 OpenCV 모듈 설정등을 위해 필요합니다. 
- libjpeg-dev libtiff5-dev libjasper-dev libpng12-dev : 특정 포맷의 이미지 파일을 불러오거나 기록하기 위해 필요한 패키지들
- libavcodec-dev libavformat-dev libswscale-dev libxvidcore-dev libx264-dev libxine2-dev : 특정 코덱의 비디오 파일/스트리밍을 읽어오거나 기록하기 위해 필요한 FFmpeg 관련 패키지들
- Video4Linux 패키지 : 리눅스에서 실시간 비디오 캡처를 지원하기 위한 디바이스 드라이버와 API를 포함하고 있습니다. 
- GStreamer 관련 패키지 : 특정 코덱의 비디오 파일/스트리밍을 읽어오거나 기록하기 위해 필요
- gtk2 : OpenCV에서는 highgui 모듈을 사용하여 자체적으로 윈도우 생성하여 이미지나 영상을 보여줍니다.  
윈도우 생성 등의 GUI를 위해 gtk 또는 qt를 선택해서 사용가능합니다. 
- mesa-utils libgl1-mesa-dri libgtkgl2.0-dev libgtkglext1-dev : OpenGL 지원하기 위해 필요한 라이브러리
- libatlas-base-dev gfortran libeigen3-dev : OpenCV 최적화를 위해 사용되는 라이브러리들 
- python2.7-dev python3-dev python-numpy python3-numpy : python2.7-dev와 python3-dev 패키지는 파이썬을 위한 헤더파일과 라이브러리가 포함된  패키지들입니다. Numpy는 매트릭스 연산등을 빠르게 처리할 수 있어서 OpenCV Python에서 사용됩니다. 

등등이 있습니다.

----------------------------------------------
face_part1.py : 사용자 얼굴 등록 - 학습할 얼굴을 촬영하는 단계.
  흑백으로 얼굴 크기 200x200 만큼 얼굴을 인식 -> 촬영 / 총 100장
  Haar Cascades를 이용해 얼굴을 검출하고 저장하는 방식입니다.
  
  Haar은 특징기반 다단계 분류자를 이용한 효과적인 물체 검출 방법입니다. 이는 검출할 대상이 되는 물체가 있는 이미지와 없는 이미지를 최대한 많이 활용해서 다단계 함수를 훈련시키는 기계학습 방식입니다.
  part1.py 파일의 알고리즘은 분류자를 훈련시키기 위해 많은 훈련용 이미지가 필요합니다. 본 프로젝트에서는 사람A의 얼굴 사진을 100장을 가지고 합니다. 얼굴 사진을 가지고 특징들을 추출합니다. 

많은 특징을 계산하기 위해 이미지에 적용할 모든 가능한 크기와 위치를 고려해야 합니다. 24X24 크기의 이미지만 해도 160000개 이상의 특징 결과 값이 존재하게 됩니다. 본 프로젝트에서는 200X200 해상도 크기만큼 검출한 얼굴의 특징들을 추출하게 됩니다. 

모든 훈련 이미지들에 대해 각각의 특징을 적용하게 됩니다. 각 특징에 대해, 이미지 상에 얼굴이 있는지 없는지를 분류될 최고의 임계값을 찾습니다. 즉 이는 얼굴 이미지인지 얼굴이 아닌 이미지인지를 분류합니다. 

여기서 본 프로젝트는 haarcascade_frontalface_default.xml 파일을 이용해서 특징을 추출하고 인식합니다. 얼굴의 경우 얼굴에서 보여주는 패턴, 눈이면 눈이 보여주는 이미지 패턴을 정리해 놓은 것입니다.

part1.py 파일에서는 카메라를 실행하여 카메라를 흑백으로 처리하고 카메라는 얼굴을 찾습니다. 찾은 얼굴이 없으면 "Face not Found"을 출력하고 다시 얼굴을 찾기 시작합니다. 얼굴을 찾으면 해당 얼굴 크기 만큼 잘라서 얼굴 이미지 크기를 200x200으로 조정하고 faces폴더에 jpg 파일로 저장하고 counter가 1 올라갑니다. 

counter가 100이 될 경우 프로그램이 종료됩니다. 
  
  

face_part2.py : 사용자 얼굴을 학습, part1에서 촬영한 사진 100장을 학습시키는 단계.
  촬영한 얼굴 사진 100장을 학습합니다. part2는 faces폴더에 있는 파일 리스트를 얻고 100개 개수 만큼 반복하며 faces의 이미지를 불러와서 리스트에 이미지를 바이트 배열로 100개의 이미지를 추가합니다. 
  
  이미지 추가가 완료되면 학습 모델을 생성하고 모델 학습을 시작하고 종료하게 됩니다. 

face_part3.py : 얼굴 인식 (최종 실행파일)
  카메라를 실행하고 실시간으로 인식되는 얼굴을 전달합니다. 미리 학습한 사진과 인식되는 얼굴을 비교 인식 하게 되어 유사도 측정합니다. 유사치를 측정하여 이미 part3에서 설정한 유사치를 넘게되면 UNLOCK를 출력하며 해당 함수를 실행하게 되어있습니다. 
  
 # 단점
  
   1. 카메라 시스템은 웹캠으로 실시간으로 얼굴을 인식한다는 개념보다는 캠으로부터 인식되는 얼굴을 사진 한장씩 읽어 얼굴을 검출하게 됩니다. 얼굴이 검출되거나 얼굴이 검출되지 않을 경우 사진 한장씩 읽어드리는 시간이 발생해 카메라가 약 2초간 딜레이가 발생하게 됩니다. 만약 카메라 view를 통해 실시간으로 보게 된다면 얼굴 검출 단계에서 약간의 딜레이가 발생해 멈춤 현상처럼 오인할 수 있습니다.
  
  2. 본 프로그램은 아직 1명의 사용자만 등록해서 얼굴을 인식하고 시스템을 동작할 수 있습니다.
  여러 사용자를 등록하기 위해서는 faces/사람A,B.....N 의 폴더를 생성해서 여러 사용자들의 얼굴을 등록할 수 있습니다. 
  
  if __name__ == "__main__":
    take_pictures('BAEK') 의 코드를 part1.py 마지막에 추가하면 faces/BAEK 폴더가 생성되고 이곳에 100장의 사진을 카메라로 찍어 저장하게 됩니다. 그렇게 되면 part2의 학습에서 약간의 코드 수정이 발생하게 되는데 이중 경로 설정을 정확하게 해야합니다. data_path = 'faces/' + name + '/'
    
  3. 본 프로그램은 얼굴을 인식하여 도어락 시스템을 작동하게 됩니다. 도어락 시스템이 작동하면 방금 검출된 얼굴은 종료가 되고 도어락은 열리지만 만약 열리고도 얼굴을 계속 검출하여 유사치가 맞을 경우 도어락이 잠긴 후에도 다시 열리게 된다는 단점이 발생합니다. 그 이유는 방금 전에 검출한 얼굴은 종료가 되지만 프로그램 자체는 종료되지 않아 카메라가 얼굴을 찾게 됩니다. 
  
  이에 경우 해결점은 얼굴이 인식되고 도어락이 열리는 점에서 프로그램을 종료하고 만약 얼굴 인식/도어락을 열기 위해서는 프로그램을 실행해야 하는데 그 방법에서는 여러가지가 있지만 물체인식센서로 움직임 감지시 실행 또는 버튼 등을 이용해서 프로그램을 실행하는 방법이 있다고 생각됩니다. 

